# LLM Provider Configuration
quarkus.langchain4j.chat-model.provider=openai

# AI model configuration
quarkus.langchain4j.log-requests=true
quarkus.langchain4j.log-responses=true
quarkus.log.level=INFO

quarkus.langchain4j.openai.api-key=${OPENAI_API_KEY}
quarkus.langchain4j.openai.chat-model.model-name=gpt-4o
quarkus.langchain4j.openai.chat-model.temperature=0
quarkus.langchain4j.openai.timeout=180s

# Server Configuration
quarkus.http.port=8888

# Logging configuration
%dev.quarkus.log.category."dev.langchain4j".level=DEBUG
%dev.quarkus.log.category."dev.langchain4j.agentic".level=DEBUG
%dev.quarkus.log.category."com.demo".level=DEBUG